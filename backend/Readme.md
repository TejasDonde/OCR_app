# ðŸŽ¯ Complete Backend Setup Checklist

## ðŸ“‹ Files Created

Your complete backend structure should look like this:

```
backend/
â”‚
â”œâ”€â”€ main.py                        âœ… FastAPI app with all 4 endpoints
â”œâ”€â”€ full_pipeline.py               âš ï¸  REPLACE with your actual pipeline
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py               âœ… Create empty file
â”‚   â”œâ”€â”€ file_manager.py           âœ… Directory & upload helpers
â”‚   â””â”€â”€ zipper.py                 âœ… Output compression
â”‚
â”œâ”€â”€ uploads/                       âœ… Auto-created on first run
â”‚
â”œâ”€â”€ requirements.txt               âœ… All dependencies
â”œâ”€â”€ .env.example                   âœ… Template for credentials
â”œâ”€â”€ .env                           âš ï¸  Create from .env.example
â”‚
â”œâ”€â”€ README.md                      âœ… Complete documentation
â””â”€â”€ test_backend.py                âœ… Testing script (optional)
```

## ðŸ”§ Step-by-Step Setup

### 1. Create Directory Structure

```bash
mkdir -p backend/utils
cd backend
touch utils/__init__.py
```

### 2. Copy All Files

Save each artifact as the corresponding file:

- `main.py` â†’ Main FastAPI application
- `utils/file_manager.py` â†’ File handling utilities
- `utils/zipper.py` â†’ Zip creation utility
- `full_pipeline.py` â†’ Your pipeline (replace sample)
- `requirements.txt` â†’ Dependencies
- `.env.example` â†’ Environment template
- `README.md` â†’ Documentation
- `test_backend.py` â†’ Test script (optional)

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment

```bash
cp .env.example .env
nano .env  # or use your preferred editor
```

Add your Azure credentials:
```
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-actual-key
AZURE_OPENAI_DEPLOYMENT=gpt-4
```

### 5. Update Your Pipeline Script

**CRITICAL:** Replace the sample `full_pipeline.py` with your actual code.

Your script MUST have:

âœ… Folder variables at the top (will be auto-updated by backend):
```python
INPUT_FOLDER = "default"
TEMP_TXT_FOLDER = "default"
OUTPUT_JSON_FOLDER = "default"
OUTPUT_EXCEL_FOLDER = "default"
```

âœ… Three main functions:
```python
def convert_pdfs_to_text():
    # Read from INPUT_FOLDER
    # Write to TEMP_TXT_FOLDER
    pass

def extract_data_with_ai():
    # Read from TEMP_TXT_FOLDER
    # Call Azure OpenAI
    # Write to OUTPUT_JSON_FOLDER
    pass

def convert_json_to_excel():
    # Read from OUTPUT_JSON_FOLDER
    # Write to OUTPUT_EXCEL_FOLDER
    pass
```

âŒ Do NOT hardcode paths inside functions
âŒ Do NOT change the function names
âœ… Use the folder variables everywhere

### 6. Test Locally

```bash
# Start backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

In another terminal:
```bash
# Run test script
python test_backend.py
```

Or test manually:
```bash
# Health check
curl http://localhost:8000/

# Upload test
curl -X POST http://localhost:8000/upload \
  -F "files=@your_test.pdf"
```

### 7. Verify API Documentation

Open in browser:
- http://localhost:8000/docs (Swagger UI)
- http://localhost:8000/redoc (ReDoc)

## ðŸ” Pre-Launch Checklist

Before connecting your frontend:

- [ ] Backend starts without errors
- [ ] All 4 endpoints return 200 status
- [ ] Test upload creates proper folder structure
- [ ] Pipeline runs without crashing
- [ ] Status updates correctly during processing
- [ ] outputs.zip is created after pipeline completes
- [ ] Download endpoint returns valid zip file
- [ ] CORS is configured for your frontend URL

## ðŸŽ¨ Frontend Integration

Your React frontend should:

1. **Upload Files** â†’ `POST /upload` â†’ Get `task_id`
2. **Start Processing** â†’ `POST /start/{task_id}`
3. **Poll Status** â†’ `GET /status/{task_id}` (every 2-3 seconds)
4. **Download Results** â†’ `GET /download/{task_id}` (when finished)

Example frontend fetch:

```javascript
// Upload
const formData = new FormData();
files.forEach(file => formData.append('files', file));

const uploadRes = await fetch('http://localhost:8000/upload', {
  method: 'POST',
  body: formData
});
const { task_id } = await uploadRes.json();

// Start
await fetch(`http://localhost:8000/start/${task_id}`, {
  method: 'POST'
});

// Poll status
const interval = setInterval(async () => {
  const statusRes = await fetch(`http://localhost:8000/status/${task_id}`);
  const status = await statusRes.json();
  
  if (status.status === 'finished') {
    clearInterval(interval);
    // Download
    window.location.href = `http://localhost:8000/download/${task_id}`;
  }
}, 2000);
```

## ðŸš¨ Common Issues

### "Module not found: full_pipeline"
- Ensure `full_pipeline.py` is in the same directory as `main.py`
- Check for typos in import statement

### "CORS error" from frontend
- Update `allow_origins` in `main.py` to match your frontend URL
- Example: `allow_origins=["http://localhost:3000"]`

### Pipeline fails silently
- Check console where uvicorn is running
- Verify Azure credentials in `.env`
- Test your pipeline script independently first

### "Task not found" errors
- Status is stored in memory (resets on server restart)
- Use persistent storage (Redis/DB) for production

### Uploads folder not created
- Should auto-create on first upload
- Manually create: `mkdir -p backend/uploads`

## ðŸ“¦ Production Deployment

For production:

1. **Change CORS settings** to specific frontend domain
2. **Use environment variables** for all secrets
3. **Add authentication** if needed
4. **Use persistent storage** for task status (Redis/PostgreSQL)
5. **Set up logging** for debugging
6. **Add rate limiting** to prevent abuse
7. **Configure proper file cleanup** to manage disk space

## ðŸŽ‰ You're Ready!

Once all checkboxes are complete:

âœ… Backend is running on http://localhost:8000
âœ… API docs accessible at /docs
âœ… Test script passes all tests
âœ… Frontend can connect and upload files

Your PDF â†’ Excel pipeline is now fully operational! ðŸš€